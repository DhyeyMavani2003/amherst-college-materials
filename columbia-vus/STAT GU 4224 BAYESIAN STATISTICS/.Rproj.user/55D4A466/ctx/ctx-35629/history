mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
school1_pred = rnorm(10000, school1_theta, sqrt(school1_sigma2))
school2_pred = rnorm(10000, school2_theta, sqrt(school2_sigma2))
school3_pred = rnorm(10000, school3_theta, sqrt(school3_sigma2))
mean(school1_pred < school2_pred & school2_pred < school3_pred)
mean(school1_pred < school3_pred & school3_pred < school2_pred)
mean(school2_pred < school1_pred & school1_pred < school3_pred)
mean(school2_pred < school3_pred & school3_pred < school1_pred)
mean(school3_pred < school1_pred & school1_pred < school2_pred)
mean(school3_pred < school2_pred & school2_pred < school1_pred)
mean(school1_theta > school2_theta & school1_theta > school3_theta)
mean(school1_pred > school2_pred & school1_pred > school3_pred)
mean(school1_theta > school2_theta & school1_theta > school3_theta)
mean(school1_pred > school2_pred & school1_pred > school3_pred)
gibbs_sampler <- function(c, S=10000) {
x <- numeric(S)
y <- numeric(S)
y[1] <- runif(1, 0, 1)
for (i in 2:S) {
x[i] <- runif(1, max(y[i-1]-c, 0), min(y[i-1]+c, 1))
y[i] <- runif(1, max(x[i]-c, 0), min(x[i]+c, 1))
}
return(list(x=x, y=y))
}
# Test the sampler
c_values <- c(0.25, 0.05, 0.02)
for (c in c_values) {
res <- gibbs_sampler(c)
x <- res$x
y <- res$y
cat(paste("c =", c, "\n"))
cat(paste("Mean of x:", mean(x), "\n"))
cat(paste("Mean of y:", mean(y), "\n"))
}
par(mfrow=c(2, 2))
for (i in seq_along(c_values)) {
res <- gibbs_sampler(c_values[i])
x <- res$x
y <- res$y
plot(x, type="l",
par(mfrow=c(2, 2))
for (i in seq_along(c_values)) {
res <- gibbs_sampler(c_values[i])
x <- res$x
y <- res$y
# Traceplots
plot(res$x, type="l", main=paste("Traceplot of x, c =", c_values[i]))
plot(res$y, type="l", main=paste("Traceplot of y, c =", c_values[i]))
# Scatterplot
plot(res$x, res$y, main=paste("Scatterplot of (x, y), c =", c_values[i]))
}
par(mfrow=c(2, 2))
for (i in seq_along(c_values)) {
res <- gibbs_sampler(c_values[i])
x <- res$x
y <- res$y
# Traceplots
plot(res$x, type="l", main=paste("Traceplot of x, c =", c_values[i]))
plot(res$y, type="l", main=paste("Traceplot of y, c =", c_values[i]))
# Scatterplot
plot(res$x, res$y, main=paste("Scatterplot of (x, y), c =", c_values[i]))
}
library(mvtnorm)
# Define observed data
data <- matrix(c(-3.3, -2.6, 0.1, -0.2, -1.1, -1.5, 2.7, 1.5, 2.0, 1.9, -0.4, -0.3), ncol = 2)
# Define grid of values for rho
rho_grid <- seq(0, 1, length.out = 1000)
# Define prior density function
prior <- rep(1, length(rho_grid))
# Define likelihood function
likelihood <- sapply(rho_grid, function(rho) {
mean(dmvnorm(data, mean = c(0,0), sigma = matrix(c(1, rho, rho, 1), nrow = 2), log = TRUE))
})
# Compute unnormalized posterior density function
posterior_unnorm <- prior * exp(likelihood)
# Numerically integrate to obtain posterior density function
posterior <- posterior_unnorm / sum(posterior_unnorm)
# Plot posterior distribution
plot(rho_grid, posterior, type = "l", xlab = "Correlation coefficient rho", ylab = "Posterior density")
# Compute posterior mean, median, mode, and 95% interval
post_mean <- sum(rho_grid * posterior)
post_median <- rho_grid[which.min(abs(cumsum(posterior) - 0.5))]
post_mode <- rho_grid[which.max(posterior)]
post_interval <- c(rho_grid[which.min(cumsum(posterior) >= 0.025)], rho_grid[which.min(cumsum(posterior) >= 0.975)])
# Print results
cat("Posterior mean: ", post_mean, "\n")
cat("Posterior median: ", post_median, "\n")
cat("Posterior mode: ", post_mode, "\n")
cat("95% posterior interval: [", post_interval[1], ", ", post_interval[2], "]\n")
library(mvtnorm)
# Define observed data
data <- matrix(c(-3.3, -2.6, 0.1, -0.2, -1.1, -1.5, 2.7, 1.5, 2.0, 1.9, -0.4, -0.3), ncol = 2)
# Define grid of values for rho
rho_grid <- seq(0, 1, length.out = 1000)
# Define prior density function
prior <- rep(1, length(rho_grid))
# Define likelihood function
likelihood <- sapply(rho_grid, function(rho) {
mean(dmvnorm(data, mean = c(0,0), sigma = matrix(c(1, rho, rho, 1), nrow = 2), log = TRUE))
})
# Compute unnormalized posterior density function
posterior_unnorm <- prior * exp(likelihood)
# Numerically integrate to obtain posterior density function
posterior <- posterior_unnorm / sum(posterior_unnorm)
# Plot posterior distribution
plot(rho_grid, posterior, type = "l", xlab = "Correlation coefficient rho", ylab = "Posterior density")
# Compute posterior mean, median, mode, and 95% interval
post_mean <- sum(rho_grid * posterior)
post_median <- rho_grid[which.min(abs(cumsum(posterior) - 0.5))]
post_mode <- rho_grid[which.max(posterior)]
post_interval <- c(rho_grid[which.min(cumsum(posterior) >= 0.025)], rho_grid[which.min(cumsum(posterior) >= 0.975)])
# Print results
cat("Posterior mean: ", post_mean, "\n")
cat("Posterior median: ", post_median, "\n")
cat("Posterior mode: ", post_mode, "\n")
cat("95% posterior interval: [", post_interval[1], ", ", post_interval[2], "]\n")
library(mvtnorm)
# Define observed data
data <- matrix(c(-3.3, -2.6, 0.1, -0.2, -1.1, -1.5, 2.7, 1.5, 2.0, 1.9, -0.4, -0.3), ncol = 2)
# Define grid of values for rho
rho_grid <- seq(0, 1, length.out = 10000)
# Define prior density function
prior <- rep(1, length(rho_grid))
# Define likelihood function
likelihood <- sapply(rho_grid, function(rho) {
mean(dmvnorm(data, mean = c(0,0), sigma = matrix(c(1, rho, rho, 1), nrow = 2), log = TRUE))
})
# Compute unnormalized posterior density function
posterior_unnorm <- prior * exp(likelihood)
# Numerically integrate to obtain posterior density function
posterior <- posterior_unnorm / sum(posterior_unnorm)
# Plot posterior distribution
plot(rho_grid, posterior, type = "l", xlab = "Correlation coefficient rho", ylab = "Posterior density")
# Compute posterior mean, median, mode, and 95% interval
post_mean <- sum(rho_grid * posterior)
post_median <- rho_grid[which.min(abs(cumsum(posterior) - 0.5))]
post_mode <- rho_grid[which.max(posterior)]
post_interval <- c(rho_grid[which.min(cumsum(posterior) >= 0.025)], rho_grid[which.min(cumsum(posterior) >= 0.975)])
# Print results
cat("Posterior mean: ", post_mean, "\n")
cat("Posterior median: ", post_median, "\n")
cat("Posterior mode: ", post_mode, "\n")
cat("95% posterior interval: [", post_interval[1], ", ", post_interval[2], "]\n")
library(mvtnorm)
# Define observed data
data <- matrix(c(-3.3, -2.6, 0.1, -0.2, -1.1, -1.5, 2.7, 1.5, 2.0, 1.9, -0.4, -0.3), ncol = 2)
# Define grid of values for rho
rho_grid <- seq(0, 1, length.out = 10000)
# Define prior density function
prior <- rep(1, length(rho_grid))
# Define likelihood function
likelihood <- sapply(rho_grid, function(rho) {
mean(dmvnorm(data, mean = c(0,0), sigma = matrix(c(1, rho, rho, 1), nrow = 2), log = TRUE))
})
# Compute unnormalized posterior density function
posterior_unnorm <- prior * exp(likelihood)
# Numerically integrate to obtain posterior density function
posterior <- posterior_unnorm / sum(posterior_unnorm)
# Plot posterior distribution
plot(rho_grid, posterior, type = "l", xlab = "Correlation coefficient rho", ylab = "Posterior density")
# Compute posterior mean, median, mode, and 95% interval
post_mean <- sum(rho_grid * posterior)
post_median <- rho_grid[which.min(abs(cumsum(posterior) == 0.5))]
post_mode <- rho_grid[which.max(posterior)]
post_interval <- c(rho_grid[which.min(cumsum(posterior) >= 0.025)], rho_grid[which.min(cumsum(posterior) >= 0.975)])
# Print results
cat("Posterior mean: ", post_mean, "\n")
cat("Posterior median: ", post_median, "\n")
cat("Posterior mode: ", post_mode, "\n")
cat("95% posterior interval: [", post_interval[1], ", ", post_interval[2], "]\n")
library(mvtnorm)
# Define observed data
data <- matrix(c(-3.3, -2.6, 0.1, -0.2, -1.1, -1.5, 2.7, 1.5, 2.0, 1.9, -0.4, -0.3), ncol = 2)
# Define grid of values for rho
rho_grid <- seq(0, 1, length.out = 10000)
# Define prior density function
prior <- rep(1, length(rho_grid))
# Define likelihood function
likelihood <- sapply(rho_grid, function(rho) {
mean(dmvnorm(data, mean = c(0,0), sigma = matrix(c(1, rho, rho, 1), nrow = 2), log = TRUE))
})
# Compute unnormalized posterior density function
posterior_unnorm <- prior * exp(likelihood)
# Numerically integrate to obtain posterior density function
posterior <- posterior_unnorm / sum(posterior_unnorm)
# Plot posterior distribution
plot(rho_grid, posterior, type = "l", xlab = "Correlation coefficient rho", ylab = "Posterior density")
# Compute posterior mean, median, mode, and 95% interval
post_mean <- sum(rho_grid * posterior)
post_median <- rho_grid[which.min(abs(cumsum(posterior) - 0.5) == 0)]
post_mode <- rho_grid[which.max(posterior)]
post_interval <- c(rho_grid[which.min(cumsum(posterior) >= 0.025)], rho_grid[which.min(cumsum(posterior) >= 0.975)])
# Print results
cat("Posterior mean: ", post_mean, "\n")
cat("Posterior median: ", post_median, "\n")
cat("Posterior mode: ", post_mode, "\n")
cat("95% posterior interval: [", post_interval[1], ", ", post_interval[2], "]\n")
data = scan("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- scan("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- scan("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")[,1]
data <- scan("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")[1,]
install.packages("haven")
library(haven)
data <- read.dat("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
#install.packages("haven")
library(haven)
data <- read_dta("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- scan("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/school1.dat")
data
x = structure(c(59, 43, 34, 32, 42, 38, 55, 67, 64, 45, 49, 72, 34,
70, 34, 50, 41, 52, 60, 34, 28, 35, 77, 39, 46, 26, 38, 43, 68,
86, 77, 60, 50, 59, 38, 48, 55, 58, 54, 60, 75, 47, 48, 33),
.Dim = c(22L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
mu0<-c(0,0)
L0<-matrix( c(10000,0,0,10000),nrow=2,ncol=2)
nu0<-4
S0<-matrix( c(100,0,0,100),nrow=2,ncol=2)
n<-dim(x)[1]
n
# Data from the textbook of pretest and posttest score
x = structure(c(59, 43, 34, 32, 42, 38, 55, 67, 64, 45, 49, 72, 34,
70, 34, 50, 41, 52, 60, 34, 28, 35, 77, 39, 46, 26, 38, 43, 68,
86, 77, 60, 50, 59, 38, 48, 55, 58, 54, 60, 75, 47, 48, 33),
.Dim = c(22L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
mu0<-c(0,0)
L0<-matrix( c(10000,0,0,10000),nrow=2,ncol=2)
nu0<-4
S0<-matrix( c(100,0,0,100),nrow=2,ncol=2)
n<-dim(x)[1]
xbar = apply(x, 2, mean)
Sigma<-cov(x) ; THETA<-SIGMA<-NULL
library(MASS) # for the mvrnorm function
# install.packages("MCMCpack")
library(MCMCpack) # for the riwish function
for(s in 1:20000)
{
###update theta
Ln<-solve( solve(L0) + n*solve(Sigma) )
mun<-Ln%*%( solve(L0)%*%mu0 + n*solve(Sigma)%*% xbar )
theta = mvrnorm(1,mun,Ln)
###update Sigma
Sn<- S0 + ( t(x)-c(theta) )%*%t( t(x)-c(theta) )
Sigma<-riwish(nu0+n, Sn)
# Sigma<-solve( rwish(1, nu0+n, solve(Sn)) )
# Update the output
THETA = rbind(THETA,theta)
SIGMA = rbind(SIGMA,c(Sigma)) # notice the Sigma matrix is vectorized
}
quantile(THETA[,1]-THETA[,2], prob=c(.025,.5,.975) )
mean( THETA[,1] - THETA[,2])
mean( THETA[,1] > THETA[,2])
hist(THETA[,2])
hist(THETA[,1], add = T, col = "red")
bivn.kde <- kde2d(THETA[,1], THETA[,2], n = 200)
contour(bivn.kde, nlevels = 50)
apply(THETA, 2, mean) # posterior mean of theta
cov(THETA) # covariance matrix of the posterior distribution of theta
# Compare to covariance of prior distribution
L0
#install.packages("emdbook")
library(emdbook)
library(coda)
HPDregionplot(mcmc(THETA), add = T, col = "red")
abline(a=0,b=1, col="red")
data <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data
data <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat", header = FALSE)
data
data <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data
data <- read.table("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data$V1
data <- read.data("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read.dta("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read.dat("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read.coda("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
data <- read_dta("http://www2.stat.duke.edu/~pdh10/FCBS/Exercises/agehw.dat")
x = structure(c(53,38,40,39,35,32,40,36,44,47,48,47,33,31,68,72,37,45,38,48,32,27,70,71,56,55,24,21,29,26,28,24,66,62,68,60,59,53,54,53,43,42,31,32,39,29,51,38,43,42,34,33,43,40,71,65,40,35,22,17,47,50,51,50,66,61,32,29,45,41,64,57,38,30,40,37,60,28,70,64,28,26,38,38,36,29,35,39,37,31,59,65,36,30,40,39,44,40,37,36,47,44,35,31,31,41,40,25,22,43,34,41,43,34,28,39,36,35,32,34,33,44,41,42,41,26,28,33,32,68,68,33,35,47,40,73,50,39,34,65,61,26,26,33,32,79,61,70,62,40,33,56,57,31,28,53,47,70,68,61,61,28,26,26,24,43,29,43,46,32,32,49,45,51,43,47,45,52,47,46,45,43,40,24,23,33,35,34,34,75,55,52,52,38,26,42,41,48,42),.Dim = c(100L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
# Data from the textbook of pretest and posttest score
x = structure(c(53,38,40,39,35,32,40,36,44,47,48,47,33,31,68,72,37,45,38,48,32,27,70,71,56,55,24,21,29,26,28,24,66,62,68,60,59,53,54,53,43,42,31,32,39,29,51,38,43,42,34,33,43,40,71,65,40,35,22,17,47,50,51,50,66,61,32,29,45,41,64,57,38,30,40,37,60,28,70,64,28,26,38,38,36,29,35,39,37,31,59,65,36,30,40,39,44,40,37,36,47,44,35,31,31,41,40,25,22,43,34,41,43,34,28,39,36,35,32,34,33,44,41,42,41,26,28,33,32,68,68,33,35,47,40,73,50,39,34,65,61,26,26,33,32,79,61,70,62,40,33,56,57,31,28,53,47,70,68,61,61,28,26,26,24,43,29,43,46,32,32,49,45,51,43,47,45,52,47,46,45,43,40,24,23,33,35,34,34,75,55,52,52,38,26,42,41,48,42),.Dim = c(100L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
y <- c(53,38,40,39,35,32,40,36,44,47,48,47,33,31,68,72,37,45,38,48,32,27,70,71,56,55,24,21,29,26,28,24,66,62,68,60,59,53,54,53,43,42,31,32,39,29,51,38,43,42,34,33,43,40,71,65,40,35,22,17,47,50,51,50,66,61,32,29,45,41,64,57,38,30,40,37,60,28,70,64,28,26,38,38,36,29,35,39,37,31,59,65,36,30,40,39,44,40,37,36,47,44,35,31,31,41,40,25,22,43,34,41,43,34,28,39,36,35,32,34,33,44,41,42,41,26,28,33,32,68,68,33,35,47,40,73,50,39,34,65,61,26,26,33,32,79,61,70,62,40,33,56,57,31,28,53,47,70,68,61,61,28,26,26,24,43,29,43,46,32,32,49,45,51,43,47,45,52,47,46,45,43,40,24,23,33,35,34,34,75,55,52,52,38,26,42,41,48,42)
y
y <- c(53,38,40,39,35,32,40,36,44,47,48,47,33,31,68,72,37,45,38,48,32,27,70,71,56,55,24,21,29,26,28,24,66,62,68,60,59,53,54,53,43,42,31,32,39,29,51,38,43,42,34,33,43,40,71,65,40,35,22,17,47,50,51,50,66,61,32,29,45,41,64,57,38,30,40,37,60,28,70,64,28,26,38,38,36,29,35,39,37,31,59,65,36,30,40,39,44,40,37,36,47,44,35,31,31,41,40,25,22,43,34,41,43,34,28,39,36,35,32,34,33,44,41,42,41,26,28,33,32,68,68,33,35,47,40,73,50,39,34,65,61,26,26,33,32,79,61,70,62,40,33,56,57,31,28,53,47,70,68,61,61,28,26,26,24,43,29,43,46,32,32,49,45,51,43,47,45,52,47,46,45,43,40,24,23,33,35,34,34,75,55,52,52,38,26,42,41,48,42)
length(y)
y <- c(53,38,40,39,35,32,40,36,44,47,48,47,33,31,68,72,37,45,38,48,32,27,70,71,56,55,24,21,29,26,28,24,66,62,68,60,59,53,54,53,43,42,31,32,39,29,51,38,43,42,34,33,43,40,71,65,40,35,22,17,47,50,51,50,66,61,32,29,45,41,64,57,38,30,40,37,60,28,70,64,28,26,38,38,36,29,35,39,37,31,59,65,36,30,40,39,44,40,37,36,47,44,35,31,31,31,41,40,25,22,43,34,41,43,34,28,39,36,35,32,34,33,44,41,42,41,26,28,33,32,68,68,33,35,47,40,73,50,39,34,65,61,26,26,33,32,79,61,70,62,40,33,56,57,31,28,53,47,70,68,61,61,28,26,26,24,43,29,43,46,32,32,49,45,51,43,47,45,52,47,46,45,43,40,24,23,33,35,34,34,75,55,52,52,38,26,42,41,48,42)
length(y)
# Data from the textbook of pretest and posttest score
x = structure(y,.Dim = c(100L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
mu0<-c(0,0)
L0<-matrix( c(10000,0,0,10000),nrow=2,ncol=2)
nu0<-4
S0<-matrix( c(100,0,0,100),nrow=2,ncol=2)
n<-dim(x)[1]
xbar = apply(x, 2, mean)
Sigma<-cov(x) ; THETA<-SIGMA<-NULL
library(MASS) # for the mvrnorm function
# install.packages("MCMCpack")
library(MCMCpack) # for the riwish function
for(s in 1:20000)
{
###update theta
Ln<-solve( solve(L0) + n*solve(Sigma) )
mun<-Ln%*%( solve(L0)%*%mu0 + n*solve(Sigma)%*% xbar )
theta = mvrnorm(1,mun,Ln)
###update Sigma
Sn<- S0 + ( t(x)-c(theta) )%*%t( t(x)-c(theta) )
Sigma<-riwish(nu0+n, Sn)
# Sigma<-solve( rwish(1, nu0+n, solve(Sn)) )
# Update the output
THETA = rbind(THETA,theta)
SIGMA = rbind(SIGMA,c(Sigma)) # notice the Sigma matrix is vectorized
}
quantile(THETA[,1]-THETA[,2], prob=c(.025,.5,.975) )
mean( THETA[,1] - THETA[,2])
mean( THETA[,1] > THETA[,2])
hist(THETA[,2])
hist(THETA[,1], add = T, col = "red")
bivn.kde <- kde2d(THETA[,1], THETA[,2], n = 200)
contour(bivn.kde, nlevels = 50)
apply(THETA, 2, mean) # posterior mean of theta
cov(THETA) # covariance matrix of the posterior distribution of theta
# Compare to covariance of prior distribution
L0
#install.packages("emdbook")
library(emdbook)
library(coda)
HPDregionplot(mcmc(THETA), add = T, col = "red")
abline(a=0,b=1, col="red")
# Data from the textbook of pretest and posttest score
x = structure(y,.Dim = c(100L, 2L), .Dimnames = list(NULL, c("husband", "wife")))
mu0<-c(0,0)
L0<-matrix( c(10000,0,0,10000),nrow=2,ncol=2)
nu0<-4
S0<-matrix( c(100,0,0,100),nrow=2,ncol=2)
n<-dim(x)[1]
xbar = apply(x, 2, mean)
Sigma<-cov(x) ; THETA<-SIGMA<-NULL
library(MASS) # for the mvrnorm function
# install.packages("MCMCpack")
library(MCMCpack) # for the riwish function
for(s in 1:20000)
{
###update theta
Ln<-solve( solve(L0) + n*solve(Sigma) )
mun<-Ln%*%( solve(L0)%*%mu0 + n*solve(Sigma)%*% xbar )
theta = mvrnorm(1,mun,Ln)
###update Sigma
Sn<- S0 + ( t(x)-c(theta) )%*%t( t(x)-c(theta) )
Sigma<-riwish(nu0+n, Sn)
# Sigma<-solve( rwish(1, nu0+n, solve(Sn)) )
# Update the output
THETA = rbind(THETA,theta)
SIGMA = rbind(SIGMA,c(Sigma)) # notice the Sigma matrix is vectorized
}
quantile(THETA[,1]-THETA[,2], prob=c(.025,.5,.975) )
mean( THETA[,1] - THETA[,2])
mean( THETA[,1] > THETA[,2])
hist(THETA[,2])
hist(THETA[,1], add = T, col = "red")
bivn.kde <- kde2d(THETA[,1], THETA[,2], n = 200)
contour(bivn.kde, nlevels = 50)
apply(THETA, 2, mean) # posterior mean of theta
cov(THETA) # covariance matrix of the posterior distribution of theta
# Compare to covariance of prior distribution
L0
#install.packages("emdbook")
library(emdbook)
library(coda)
HPDregionplot(mcmc(THETA), add = T, col = "red")
abline(a=0,b=1, col="red")
# Finding the stationary distribution of a transition matrix
# Brute force:
install.packages("expm")
library(expm) # used to compute matrix power
# Define the transition matrix
(P = matrix(c(c(0.4,0.5,0.1), c(0.3,0.4,0.3), c(0.2,0.3,0.5)), nrow = 3, byrow = T))
# Check sum across = 1
apply(P,1,sum)
# Solution
(pi_bru = (P %^% 100)[1,])
# Check:
pi_bru - pi_bru%*%P
# Eigen decomposition
library(MASS) # For the ginv function
# Get the eigenvectors of P, note: R returns right eigenvectors
r=eigen(P)
(rvec=r$vectors)
# left eigenvectors are the inverse of the right eigenvectors
(lvec=ginv(r$vectors))
# The eigenvalues
(lam<-r$values)
# Two ways of checking the spectral decomposition:
## Standard definition
rvec%*%diag(lam)%*%ginv(rvec)
## With left eigenvectors
rvec%*%diag(lam)%*%lvec
# Normalize the solution
pi_eig<-lvec[1,]/sum(lvec[1,])
pi_eig
#check
sum(pi_eig)
pi_eig %*% P
# Alternative: we can also obtain the left eigenvectors as the transposes of the right eigenvectors of t(P)
r<-eigen(t(P))
V<-r$vectors
lam<-r$values
V%*%diag(lam)%*%ginv(V)
# Rate of convergence:
lam[2]
# Linear equation method
K = 3
(A = rbind(t(P-diag(rep(1, K)))[1:(K-1),], rep(1, K)))
solve (A, c(rep(0,K-1),1))
# Mixture model:
mu1 = -2
mu2 = 2
s1 = 0.6
s2 = 0.6
pd = c(0.5, 0.5)
# iid Monte Carlo sample
S = 10000
d = rbinom(S, 1, pd[1])
x = 1:S
for (i in 1:S) if (d[i] == 0) x[i] = rnorm(1, mu1, s1) else x[i] = rnorm(1, mu2, s2)
hist(x, freq = F, ylim = c(0,0.4))
grid = seq(-5, 5, len = 1000)
lines(grid, pd[1]*dnorm(grid, mu1, s1) + pd[2]*dnorm(grid, mu2, s2), lw = 2)
# Gibbs
d = 1:S
xGibbs = 1:S
for (i in 2:S)
{
if (d[i-1] == 0) xGibbs[i] = rnorm(1, mu1, s1) else xGibbs[i] = rnorm(1, mu2, s2)
d[i] = rbinom(1, 1, 1-pd[1]*dnorm(xGibbs[i], mu1, s1)/(pd[1]*dnorm(xGibbs[i], mu1, s1) + pd[2]*dnorm(xGibbs[i], mu2, s2)))
}
hist(xGibbs, freq = F, ylim = c(0,0.4))
lines(grid, pd[1]*dnorm(grid, mu1, s1) + pd[2]*dnorm(grid, mu2, s2), lw = 2)
table(d)
par(mfrow = c(1,2))
ts.plot(xGibbs)
ts.plot(x)
acf(xGibbs)
acf(x)
install.packages("coda")
library(coda)
effectiveSize(xGibbs)
effectiveSize(x)
